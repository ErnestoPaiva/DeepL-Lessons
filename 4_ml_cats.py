# -*- coding: utf-8 -*-
"""4 Curso ML - Cats.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IdLMpMRJ6DfsM4xCDwJxF20Y5jTHODSN
"""

import numpy as np
import matplotlib.pyplot as plt
import h5py

import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras import Sequential
from tensorflow.keras.activations import sigmoid

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

def load_dataset():
    train_dataset = h5py.File('train_catvnoncat.h5', "r")
    train_set_x_orig = np.array(train_dataset["train_set_x"]) # caracteristicas del conjunto de entrenamiento
    train_set_y_orig = np.array(train_dataset["train_set_y"]) # etiquetas del conjunto de entrenamiento

    test_dataset = h5py.File('test_catvnoncat.h5', "r")
    test_set_x_orig = np.array(test_dataset["test_set_x"]) # caracteristicas del conjunto de prueba
    test_set_y_orig = np.array(test_dataset["test_set_y"]) # etiquetas del conjunto de prueba

    classes = np.array(test_dataset["list_classes"]) # lista de clases
    
    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes

from google.colab import files
uploaded = files.upload()

# Cargar los datos (cat/non-cat)
TRAIN_set_x_orig, TRAIN_set_y, test_set_x_orig, test_set_y, classes = load_dataset()

print ("TRAIN_set_x_orig shape: " + str(TRAIN_set_x_orig.shape))
print ("TRAIN_set_y shape: " + str(TRAIN_set_y.shape))
print ("test_set_x_orig shape: " + str(test_set_x_orig.shape))
print ("test_set_y shape: " + str(test_set_y.shape))

# Ejemplo de una imagen
index = 3
plt.imshow(TRAIN_set_x_orig[index])
plt.title(classes[TRAIN_set_y[index]].decode("utf-8"))

# Aplanamiento de la imagen
TRAIN_set_x_flatten = TRAIN_set_x_orig.reshape(TRAIN_set_x_orig.shape[0], -1)
test_set_x_flatten =  test_set_x_orig.reshape(test_set_x_orig.shape[0], -1)

print ("TRAIN_set_x_flatten shape: " + str(TRAIN_set_x_flatten.shape))
print ("TRAIN_set_y shape: " + str(TRAIN_set_y.shape))
print ("test_set_x_flatten shape: " + str(test_set_x_flatten.shape))
print ("test_set_y shape: " + str(test_set_y.shape))

# Escalamiento de los datos
TRAIN_set_x = TRAIN_set_x_flatten/255.
test_set_x = test_set_x_flatten/255.

train_set_x, valid_set_x, train_set_y, valid_set_y = train_test_split(TRAIN_set_x, TRAIN_set_y, test_size=0.25, random_state=42)

print ("TRAIN_set_x shape: " + str(TRAIN_set_x.shape))
print ("TRAIN_set_y shape: " + str(TRAIN_set_y.shape))
print ("train_set_x shape: " + str(train_set_x.shape))
print ("train_set_y shape: " + str(train_set_y.shape))
print ("valid_set_x shape: " + str(valid_set_x.shape))
print ("valid_set_y shape: " + str(valid_set_y.shape))
print ("test_set_x shape:  " + str(test_set_x.shape))
print ("test_set_y shape:  " + str(test_set_y.shape))

# Creación del modelo
model = Sequential([
                    Dense(units=1, input_shape= [train_set_x.shape[-1]], activation=sigmoid)
                    ])

# Arquitectura del modelo
model.summary()

# Definición del optimizador, función de pérdidas y métricas
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), loss= tf.keras.losses.BinaryCrossentropy(),metrics=tf.keras.metrics.BinaryAccuracy() )

model.fit(train_set_x, train_set_y, epochs=100, batch_size=32)

# Realizar predicciones
train_pred_prob = model.predict(train_set_x)
valid_pred_prob = model.predict(valid_set_x)

# Predicción de clases
train_pred_class = train_pred_prob>0.5
valid_pred_class = valid_pred_prob>0.5

# Metricas
Metricas = model.evaluate(train_set_x, train_set_y , verbose=0)
Metricas

# Accuracy
acc_train = accuracy_score(train_set_y, train_pred_class)
acc_valid = accuracy_score(valid_set_y, valid_pred_class)

print('Train Acc: ', acc_train)
print('Validation Acc: ', acc_valid)

# Creación del modelo
modelo_final = Sequential([
                    Dense(units=1, input_shape= [TRAIN_set_x.shape[-1]], activation=sigmoid)
                    ])

# Arquitectura del modelo
modelo_final.summary()

# Definición del optimizador, función de pérdidas y métricas
modelo_final.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), loss= tf.keras.losses.BinaryCrossentropy(),metrics=tf.keras.metrics.BinaryAccuracy() )

modelo_final.fit(TRAIN_set_x, TRAIN_set_y, epochs=100, batch_size=32)

# Realizar predicciones
TRAIN_pred_prob = modelo_final.predict(TRAIN_set_x)
test_pred_prob = modelo_final.predict(test_set_x)

# Predicción de clases
TRAIN_pred_class = TRAIN_pred_prob>0.5
test_pred_class = test_pred_prob>0.5

# Accuracy
acc_TRAIN = accuracy_score(TRAIN_set_y, TRAIN_pred_class)
acc_test = accuracy_score(test_set_y, test_pred_class)

print('TRAIN Acc: ', acc_TRAIN)
print('test Acc: ', acc_test)

# Ejemplo de una imagen de entrenamiento
index = 7
plt.imshow(TRAIN_set_x_orig[index])
plt.title(classes[TRAIN_set_y[index]].decode("utf-8"))

print(TRAIN_pred_prob[index] )

# Ejemplo de una imagen de prueba
index = 3
plt.imshow(test_set_x_orig[index])
plt.title(classes[test_set_y[index]].decode("utf-8"))

print(test_pred_prob[index] )

