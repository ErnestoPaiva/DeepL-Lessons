# -*- coding: utf-8 -*-
"""3 Curso ML - Billetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BtPr6z6E_PZbjCOD-9n67JlJItqiQkJ-

##Información sobre el conjunto de datos:

Los datos se extrajeron de imágenes tomadas de ejemplares auténticos y falsificados de billetes. Las imágenes finales tienen 400x 400 píxeles. Se obtuvieron imágenes en escala de grises con una resolución de unos 660 ppp. Se utilizó la herramienta de Transformación Wavelet para extraer las características de las imágenes.

Hay 4 variables de predicción (varianza de la imagen, asimetría, curtosis, entropía). La variable a predecir se codifica como 0 (auténtica) o 1 (falsa). Véase https://archive.ics.uci.edu/ml/datasets/banknote+authentication.
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#import h5py

import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras import Sequential
from tensorflow.keras.activations import sigmoid

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

from google.colab import files
uploaded = files.upload()

# cargar los datos
data_df = pd.read_csv("data_banknote_authentication.txt",
                           names=['Varianza',
                                  'Asimetría',
                                  'Curtosis',
                                  'Entropía', 
                                  'Clase'])
data_df

# Separar en características y etiquetas
data_x = data_df[['Varianza','Asimetría','Curtosis','Entropía']].to_numpy()
data_y = data_df[['Clase']].to_numpy()

# Segmentar en ENTRENAMIENTO y prueba
TRAIN_x_orig, test_x_orig, TRAIN_y, test_y = train_test_split(data_x, data_y, test_size=0.20, random_state=42)

# Dimensiones de los conjuntos de ENTRENAMIENTO y prueba
print ("TRAIN_x_orig shape: " + str(TRAIN_x_orig.shape))
print ("TRAIN_y shape: " + str(TRAIN_y.shape))
print ("test_x_orig shape: " + str(test_x_orig.shape))
print ("test_y shape: " + str(test_y.shape))

# Escalamiento de los datos
scaler = MinMaxScaler()
scaler.fit(TRAIN_x_orig)

TRAIN_x = scaler.transform(TRAIN_x_orig)
test_x = scaler.transform(test_x_orig)

# Segmentación en entrenamiento y validación
train_x, valid_x, train_y, valid_y = train_test_split(TRAIN_x, TRAIN_y, test_size=0.2, random_state=42)

# Resumen de dimensiones
print ("TRAIN_x shape: " + str(TRAIN_x.shape))
print ("TRAIN_y shape: " + str(TRAIN_y.shape))
print ("train_x shape: " + str(train_x.shape))
print ("train_y shape: " + str(train_y.shape))
print ("valid_x shape: " + str(valid_x.shape))
print ("valid_y shape: " + str(valid_y.shape))
print ("test_x shape:  " + str(test_x.shape))
print ("test_y shape:  " + str(test_y.shape))

# Creación del modelo
model = Sequential([
                    Dense(units=10, input_shape= [train_x.shape[-1]], activation=sigmoid)
                    ])

# Arquitectura del modelo
model.summary()

# Definición del optimizador, función de pérdidas y métricas
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss= tf.keras.losses.BinaryCrossentropy(),metrics=tf.keras.metrics.BinaryAccuracy() )

model.fit(train_x, train_y, epochs=200, batch_size=32)

# Realizar predicciones
train_pred_prob = model.predict(train_x)
valid_pred_prob = model.predict(valid_x)

# Predicción de clases
train_pred_class = train_pred_prob>0.5
valid_pred_class = valid_pred_prob>0.5

# Metricas
Metricas = model.evaluate(train_x, train_y , verbose=0)
Metricas

# Accuracy
acc_train = accuracy_score(train_y, train_pred_class)
acc_valid = accuracy_score(valid_y, valid_pred_class)

print('Train Acc: ', acc_train)
print('Validation Acc: ', acc_valid)

# Creación del modelo
modelo_final = Sequential([
                    Dense(units=1, input_shape= [TRAIN_x.shape[-1]], activation=sigmoid)
                    ])

# Arquitectura del modelo
modelo_final.summary()

# Definición del optimizador, función de pérdidas y métricas
modelo_final.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss= tf.keras.losses.BinaryCrossentropy(),metrics=tf.keras.metrics.BinaryAccuracy() )

modelo_final.fit(TRAIN_x, TRAIN_y, epochs=200, batch_size=32)

# Realizar predicciones
TRAIN_pred_prob = modelo_final.predict(TRAIN_x)
test_pred_prob = modelo_final.predict(test_x)

# Predicción de clases
TRAIN_pred_class = TRAIN_pred_prob>0.5
test_pred_class = test_pred_prob>0.5

# Accuracy
acc_TRAIN = accuracy_score(TRAIN_y, TRAIN_pred_class)
acc_test = accuracy_score(test_y, test_pred_class)

print('TRAIN Acc: ', acc_TRAIN)
print('test Acc: ', acc_test)

